batch_analysis_task:
  description: >
    Execute a comprehensive, distributed analysis of a large-scale codebase by coordinating the systematic processing of {total_chunks} code chunks.
            
            **Core Responsibilities:**
            
            For each chunk in {code_chunks}, perform the following analytical sequence:
            
            1. **Deep Chunk Analysis**: 
               - Conduct thorough static analysis of code structure, patterns, and relationships
               - Identify architectural patterns, design principles, and coding standards
               - Map component dependencies and inter-module communications
               - Assess code quality metrics and technical debt indicators
            
            2. **Cross-Chunk Context Tracking**:
               - Maintain awareness of previously analyzed chunks to identify recurring patterns
               - Track architectural themes and design consistency across the codebase
               - Identify potential integration points and dependency chains
               - Monitor for architectural anti-patterns and inconsistencies
            
            3. **Progressive Knowledge Synthesis**:
               - Build an evolving understanding of the overall system architecture
               - Correlate findings across chunks to identify system-wide patterns
               - Maintain a running inventory of components, their roles, and relationships
               - Document emerging insights about the codebase's architectural philosophy
            
            **Available Context:**
            - `code_chunks`: Structured collection of tokenized code segments with metadata
            - `total_chunks`: Total number of chunks for progress tracking and completion validation
            - `chunk_metadata`: File paths, token counts, and relationship indicators for each chunk
            
            **Quality Assurance Requirements:**
            - Ensure consistent analytical depth across all chunks
            - Validate that no critical architectural elements are overlooked
            - Maintain coherence between chunk-level findings and system-level insights
            - Provide progress indicators and intermediate validation checkpoints
  expected_output: >
    **Comprehensive Architectural Analysis Report** containing:

            **1. Executive Architecture Summary**
            - High-level system architecture overview with primary architectural patterns identified
            - Technology stack analysis and framework utilization assessment
            - Overall code organization philosophy and structural principles

            **2. Component Inventory & Responsibility Matrix**
            - Detailed catalog of all major components, modules, and packages
            - Clear responsibility assignments and component interaction mappings
            - Identification of core business logic, infrastructure, and utility components

            **3. Architectural Pattern Analysis**
            - Comprehensive identification of design patterns (Singleton, Factory, Observer, etc.)
            - Architectural patterns (MVC, Microservices, Layered, etc.) with implementation quality assessment
            - Anti-patterns detected and their potential impact on system maintainability

            **4. Dependency & Integration Analysis**
            - Cross-component dependency mapping with coupling strength indicators
            - External library and framework dependency assessment
            - Integration points and data flow analysis between major system components

            **5. Code Quality & Technical Debt Assessment**
            - Code complexity metrics aggregated across all chunks
            - Technical debt hotspots and refactoring opportunities
            - Consistency analysis of coding standards and best practices adherence

            **6. Actionable Recommendations**
            - Prioritized improvement suggestions for architectural enhancements
            - Refactoring opportunities with estimated impact and effort
            - Maintainability and scalability improvement recommendations
            
            **Format**: Structured markdown document with clear sections, bullet points for key findings, and summary tables where appropriate.

  agent: batch_coordinator

chunk_analysis_task:
  description: >
    Perform comprehensive static analysis of the designated code chunk with laser-focused attention to architectural significance and code quality metrics.
            
            **Target Chunk**: {current_chunk}
            **Processing Context**: Chunk {chunk_number} of {total_chunks}
            
            **Analytical Framework - Execute the following systematic evaluation:**
            
            **1. Structural Architecture Analysis**
            - **Class Hierarchy Mapping**: Identify all classes, interfaces, abstract classes, and their inheritance relationships
            - **Method Signature Analysis**: Catalog public, private, and protected methods with parameter complexity assessment
            - **Module Organization**: Evaluate package/namespace structure and logical code organization
            - **Component Boundaries**: Identify discrete functional units and their encapsulation quality
            
            **2. Design Pattern Recognition & Assessment**
            - **Creational Patterns**: Detect Factory, Builder, Singleton, Prototype implementations
            - **Structural Patterns**: Identify Adapter, Decorator, Facade, Proxy, Composite usage
            - **Behavioral Patterns**: Recognize Observer, Strategy, Command, State, Template Method patterns
            - **Architectural Patterns**: Assess MVC, Repository, Service Layer, or other architectural implementations
            - **Pattern Quality**: Evaluate correct implementation and adherence to pattern principles
            
            **3. Dependency Ecosystem Analysis**
            - **External Dependencies**: Catalog all imported libraries, frameworks, and third-party packages
            - **Internal Dependencies**: Map relationships to other modules within the codebase
            - **Dependency Injection**: Identify DI patterns and inversion of control implementations
            - **Coupling Assessment**: Evaluate tight vs. loose coupling between components
            - **Version Compatibility**: Note any version-specific dependencies or compatibility concerns
            
            **4. Functional Responsibility Mapping**
            - **Primary Business Logic**: Identify core business rules and domain-specific functionality
            - **Infrastructure Code**: Distinguish utility functions, data access, and system integration code
            - **Cross-Cutting Concerns**: Identify logging, security, validation, and error handling implementations
            - **API Boundaries**: Map public interfaces and external interaction points
            - **Data Flow**: Trace data transformation and processing pathways
            
            **5. Code Quality & Complexity Metrics**
            - **Cyclomatic Complexity**: Calculate complexity scores for critical methods and classes
            - **Cognitive Load Assessment**: Evaluate code readability and maintainability factors
            - **Technical Debt Indicators**: Identify code smells, anti-patterns, and refactoring opportunities
            - **Test Coverage Gaps**: Note areas lacking adequate test coverage based on code analysis
            - **Performance Considerations**: Highlight potential performance bottlenecks or optimization opportunities
            
            **6. Security & Best Practices Evaluation**
            - **Security Vulnerabilities**: Identify potential security risks and unsafe coding practices
            - **Code Standards Compliance**: Assess adherence to established coding conventions
            - **Documentation Quality**: Evaluate inline documentation and code self-explanation
            
            **Analysis Constraints:**
            - Maintain strict focus on the current chunk without making assumptions about external code
            - Document any dependencies or references that extend beyond the current chunk boundary
            - Provide context markers for integration with broader codebase analysis
            - Flag any incomplete patterns or structures that may span multiple chunks

  expected_output: >
    **Detailed Code Chunk Analysis Report** structured as follows:
            
    **1. Chunk Overview & Metrics**
    - File count, total lines of code, and token utilization
    - Primary programming languages and framework versions detected
    - Overall complexity score and maintainability index
    
    **2. Structural Component Inventory**
    ```
    Classes: [List with inheritance relationships]
    Interfaces: [List with implementation details]  
    Functions/Methods: [Categorized by access level and complexity]
    Constants/Enums: [Configuration and enumeration values]
    ```
    
    **3. Design Pattern Implementation Matrix**
    | Pattern Type | Pattern Name | Implementation Quality | Usage Context | Notes |
    |--------------|--------------|----------------------|---------------|--------|
    | [Category]   | [Pattern]    | [Excellent/Good/Poor] | [Where Used]  | [Comments] |
    
    **4. Dependency Analysis**
    - **External Libraries**: List with versions and usage purpose
    - **Internal Modules**: Referenced components with relationship type
    - **Coupling Strength**: Assessment of dependency tightness (High/Medium/Low)
    - **Dependency Injection**: DI pattern usage and quality assessment
    
    **5. Functional Responsibility Breakdown**
    - **Core Business Logic**: [Percentage and description]
    - **Infrastructure/Utility Code**: [Percentage and description]  
    - **Data Access Layer**: [Percentage and description]
    - **UI/Presentation Logic**: [Percentage and description]
    - **Integration/API Code**: [Percentage and description]
    
    **6. Quality Assessment & Metrics**
    ```
    Cyclomatic Complexity: [Average/Max values]
    Maintainability Index: [Score out of 100]
    Technical Debt Ratio: [Estimated hours/percentage]
    Code Coverage Gaps: [Areas needing attention]
    ```
    
    **7. Issues & Recommendations**
    - **Critical Issues**: High-priority problems requiring immediate attention
    - **Performance Concerns**: Potential bottlenecks and optimization opportunities  
    - **Security Vulnerabilities**: Identified security risks and mitigation suggestions
    - **Refactoring Opportunities**: Specific improvement suggestions with effort estimates
    - **Best Practice Violations**: Standards compliance issues and corrections needed
    
    **8. Integration Notes**
    - **External Dependencies**: Components referenced but not defined in this chunk
    - **Incomplete Patterns**: Patterns that may continue in other chunks
    - **Cross-Chunk Relationships**: Interfaces and dependencies extending beyond current scope
      
    **Format**: Well-structured markdown with tables, code snippets, and clear section headers for easy integration with batch analysis results.

  agent: software_analyst

analysis_task:
  description: >
    Conduct a comprehensive analysis of the provided repository to understand its purpose, architecture, and implementation details.
            
    **Target Repository**: {code_path}
    **Source Code Context**: {repo}

    **Primary Analysis Objectives:**
            
    **1. Project Purpose & Domain Analysis**
    - Identify and document the overall purpose and business domain of the project
    - Determine the target audience and use cases the software addresses
    - Analyze the problem domain and solution approach implemented
    - Evaluate the project's scope and functional boundaries
    
    **2. Technology Stack Assessment**
    - Catalog all technologies, programming languages, and their versions used
    - Identify APIs, frameworks, libraries, and external dependencies
    - Assess technology choices and their appropriateness for the problem domain
    - Document build tools, deployment technologies, and infrastructure requirements
    - Evaluate technology stack coherence and integration patterns
    
    **3. Component Architecture Mapping**
    - Identify and categorize all major components including:
      * **Classes**: Business entities, service classes, utility classes, data models
      * **Interfaces**: Contracts, APIs, and abstraction layers
      * **Functions/Methods**: Core business logic, utility functions, and integration points
      * **Modules/Packages**: Logical organization and namespace structure
    - Document component hierarchies and inheritance relationships
    - Map component responsibilities and functional boundaries
    
    **4. Component Interaction Analysis**
    - Trace and document interactions between major components
    - Identify data flow patterns and communication mechanisms
    - Map dependency relationships and coupling strengths
    - Analyze integration points and external system interfaces
    - Document event-driven interactions and messaging patterns
    
    **5. Architectural Patterns & Design Principles**
    - Identify implemented architectural patterns (MVC, Microservices, Layered, etc.)
    - Recognize design patterns and their usage contexts
    - Evaluate adherence to SOLID principles and other design best practices
    - Assess separation of concerns and modular design implementation
    - Document architectural decisions and their rationale where evident
    
    **6. Code Quality & Structure Assessment**
    - Evaluate overall project structure and organization
    - Assess code quality, maintainability, and technical debt indicators
    - Identify strengths in the current implementation
    - Highlight areas for improvement and potential weaknesses
    - Document coding standards and consistency across the codebase
    
    **Processing Strategy:**
    - If the codebase size is within manageable limits, perform direct comprehensive analysis
    - If the codebase is too large (context overflow risk), intelligently delegate to the batch coordinator
    - Ensure complete coverage regardless of processing approach chosen
    - Maintain analysis quality and depth consistency across all processing methods

  expected_output: >
    A detailed analysis report covering the purpose of the project, 
    the technologies, APIs, frameworks used, 
    a list of components and their interactions, 
    and architectural patterns and design principles applied.

  agent: software_analyst

code_quality_task:
  description: >
    Analyze the provided {sonarqube_json} for the {repo} project.
    Carefully examine the sections related to bugs, vulnerabilities, 
    code smells, code coverage, and duplication.
    Provide a detailed summary of each area, quantifying relevant metrics 
    and identifying the main weaknesses of the code from a quality perspective.
    Also, suggest specific improvements that could be implemented to address these issues.
    Ensure your report is comprehensive and well-structured, 
    providing all the necessary information for the documentation_writer 
    to include an exhaustive section on code quality in the README.
    If {sonarqube_json} is empty, your answer MUST BE "Not enough informations to write a report.".
    If the code coverage is sufficiently high (above 80%), acknowledge that it is good, so avoid unnecessary remarks about the remaining
    uncovered code in this case.

  expected_output: >
    ```json
    {
      "bugs": {
        "count": "Number of bugs identified",
        "major": "Number of major bugs",
        "critical": "Number of critical bugs",
        "details": "Brief description of significant bugs"
      },
      "vulnerabilities": {
        "count": "Number of vulnerabilities identified",
        "major": "Number of major vulnerabilities",
        "critical": "Number of critical vulnerabilities",
        "details": "Brief description of significant vulnerabilities"
      },
      "code_smells": {
        "count": "Number of code smells",
        "major": "Number of major code smells",
        "details": "Examples of common code smell types found"
      },
      "coverage": {
        "line_coverage": "Percentage of lines covered by tests",
        "branch_coverage": "Percentage of branches covered by tests",
        "details": "Areas with low coverage"
      },
      "duplication": {
        "lines": "Number of duplicated lines",
        "percentage": "Percentage of duplicated lines",
        "details": "Examples of duplicated code blocks"
      },
      "weaknesses": "Summary of the main code quality weaknesses identified",
      "suggested_improvements": [
        "Specific actionable suggestions to address the identified issues"
      ]
    }
    ```
  agent: sonar_quality_analyst

documentation_task:
  description: >
    Review the context you got and expand each topic into a full section for a report.
    The report must be rich, complete, and self-contained — similar in depth and scope to internal system documentation.
    Each section must be fully developed, informative, and technically meaningful.

    You are not summarizing or simplifying — you are elaborating in full.
    Explain motivations behind architectural choices, clarify roles of different modules or components, 
    and define domain-specific terminology relevant to the project, and now also include a summary and 
    interpretation of the code quality metrics and identified weaknesses from SonarQube.
    Your goal is to make the document useful for developers, architects, and stakeholders alike.
    Do not wrap the output in any code block markers like ```text, ```markdown, or triple quotes. 
    The document should be raw, clean Markdown, exactly as it would appear in the final file.
    Under no circumstances add code block delimiters at the beginning or end of the document.

    For the "Getting Started" section, you must:
      1. Explain any prerequisites (e.g., programming language version, build tool, environment setup) 
         and general build steps (e.g., how to compile the code, run tests, package or deploy).
      - Explains how to clone the repository using the URL provided as {repository_url}.
           For instance: "git clone {repository_url}"
      2. Provide an overview of how each primary module or subproject is typically used in the application:
         - One short paragraph per module/subproject describing how to integrate or invoke it,
           and the main value it brings to the system.
      3. Demonstrate minimal usage patterns or configuration references (without raw source code),
         focusing on practical guidance (e.g., how to set up environment variables, register services, or enable security).

    For the "Weaknesses and Areas for Improvement" section, synthesize the findings from both the software analyst 
    (technical debt, potential issues) and the SonarQube analyst (bugs, vulnerabilities, code smells).
    Do NOT analyze or critique the code directly.
    Instead, write it as a structured list of concrete TODOs for future releases or documentation improvements.
    These should reflect missing features, unclear responsibilities, documentation gaps, 
    integration points, or architectural areas that could be enhanced or clarified, 
    and now also include actionable items based on the identified code quality issues 
    (e.g., refactor complex modules, improve test coverage in specific areas, address high-priority vulnerabilities).
    Approach this section as a documentation and product-focused agent, not as a code reviewer.
    The output should guide the roadmap and future planning of the project, considering both functionality and code quality.

  expected_output: >
    A fully fledged, production-level report with the main topics, each expanded into a complete, standalone section,
    now including a detailed overview of the project's architecture and code quality.
    You should include weaknesses and areas for improvement, formatted as roadmap-oriented TODOs,
    incorporating both technical and code quality aspects.
    Do not include source code or code snippets.
    The output must be formatted as pure Markdown text, without wrapping the entire document in code block markers
    (no '```', no triple quotes ''', and no language identifiers like 'markdown' or 'text').
    Use regular paragraphs, headings, and sub-headings for clarity.
    The title must be the repository name only.
    
    Avoid enclosing the entire output in any kind of code block or special formatting markers.
    Output the document as clean text, as it should appear in the final README.md file.
    
    ## Overview  
    Provide a comprehensive overview of the overall project's purpose,
    architectural scope, and target use cases.  
    Clearly distinguish between the general framework or platform and the specific
    role of this repository within that broader context.  
    Explain what the project enables, who it's for, and why it exists.  
    Also include a description of the specific purpose of this repository and
    the role of each internal module in supporting the project's overall goals.

    
    ## Technology Stack
    **List and describe** only the must relevant technologies, frameworks, and libraries used in the project.
    - **Language:** [Programming Language]
    - **Frameworks:** [Frameworks Used]
    - **Libraries:** [Libraries Used]
    - **Tools:** [Tools Used]

    ## Directory Structure
    Outline the directory structure of the project with brief descriptions of each directory and file.
    Include subdirectories, modules, and relevant test locations where possible.
    For example:
    ├── src/
    │ ├── main.py - Entry point of the application
    │ ├── utils.py - Utility functions
    │ └── ...
    ├── tests/
    │ ├── test_main.py - Tests for main.py
    │ └── ...
    └── README.md - Project documentation
    
    ## Getting Started
    Provide instructions on:
      - General build steps (e.g., prerequisites, compilation, tests, packaging)
      - Required configuration or environment variables
      - Usage of each primary module: one short paragraph per module describing how to integrate
        or invoke it in an external project or application
      - For each module, clearly explain how it can be imported, added as a dependency, deployed in a compatible runtime environment,
        or activated through configuration or annotations.
        In the 'Module Usage' section, you must include at least one realistic example showing how a module can be imported and configured
        in an external project. This example must be relevant to the framework's intended usage context,
        and must reflect how an end-user would typically set it up.
      - Minimal references to usage patterns or setup steps (avoid showing raw code), focusing on practical and realistic examples.

    ## Functional Analysis
    Provide an in-depth explanation of the high-level features, responsibilities, and functional areas of the codebase.
    Address each of the following aspects in a dedicated subsection, elaborating on examples and rationale where applicable:
      ### 1. Main Responsibilities of the System
      Describe the primary duties or roles the system fulfills.
      Clarify what its core purpose is and how it manages or orchestrates various functionalities.
      Include any foundational services or abstractions the system provides.
      
      ### 2. Problems the System Solves
      Explain the specific issues or challenges the system addresses.
      Highlight real-world scenarios or user needs that the system is designed to meet,
      and illustrate how its architecture or components solve these problems.
      
      ### 3. Interaction of Modules and Components
      Detail how different modules or components communicate and collaborate.
      Discuss dependency flows, event handling, or shared interfaces.
      Emphasize any notable design patterns or architectural decisions that enable efficient interaction or loose coupling.
      
      ### 4. User-Facing vs. System-Facing Functionalities
      Differentiate the functionalities directly visible to end users (such as UIs, REST endpoints, CLI commands)
      from those meant for internal processes or other system components (e.g., background jobs, frameworks, security layers).
      Explain how each set of functionalities contributes to the overall goals of the application.
    
    Additionally, explicitly identify and document:
    - Any interface or abstract class that systematically applies common annotations,
    decorators, or behaviors across all implementing or extending classes, ensuring consistent and shared functionality.
      
    
    ## Architectural Patterns and Design Principles Applied
    List and describe all architectural patterns and design principles applied.
    Provide examples or explain how they are used within the system (e.g., Dependency Injection, Service-Oriented Architecture,
    Interceptor, Event-Driven, Role-Based Access Control, etc.).

    ## Code Quality Analysis
    Provide a summary of the code quality analysis derived from the SonarQube report. Include key metrics such as:
    - **Bugs:** Number and severity of identified bugs.
    - **Vulnerabilities:** Number and severity of identified security vulnerabilities.
    - **Code Smells:** Number and types of code smells detected.
    - **Code Coverage:** Percentage of lines and branches covered by tests.
    - **Duplication:** Percentage of duplicated code.
    Briefly explain the implications of these metrics for the project's maintainability, reliability, and security.
    If {sonarqube_json} is empty, contains an "error" key, or exactly equals "Not enough informations to write a report."
    your answer MUST BE "Not enough informations to write a report.". Do not generate any other text or commentary in this case.


    ## Weaknesses and Areas for Improvement
    Reframe weaknesses identified by the software analyst and code quality issues reported by SonarQube 
    as concrete TODO items for future releases or roadmap planning.
    Focus on functional gaps, unclear behaviors, insufficient documentation, architectural enhancements, 
    and now also include actionable items to address code quality issues 
    (e.g., refactor module X to reduce complexity, increase test coverage for feature Y, 
    address high-priority security vulnerabilities reported by SonarQube).
    Use brief descriptions and concise bullet points or checkboxes to structure the section.

    ## Further Areas of Investigation
    Identify and describe any architectural or technical elements that warrant additional exploration or clarification.
    Provide a set of items or areas that may require deeper analysis in future iterations, focusing on potential performance bottlenecks,
    scalability considerations, integrations with external systems, advanced features to be researched,
    or areas of the codebase with significant code smells or low test coverage.

    ## Attribution
    Generated with the support of ArchAI, an automated documentation system.

  agent: documentation_writer

diagram_task:
  description: >
    Generate a PlantUML {diagram_type} diagram that focuses only on the most essential elements of the architecture
    described in the provided README or context, and save it in {output_format} format.

    The {diagram_type} parameter can be:
    - 'class' for class diagrams
    - 'component' for component diagrams
    - 'sequence' for sequence diagrams
    - 'all' to generate all three diagrams (class, component, and sequence) in sequence.

    If 'all' is selected, output all diagrams in the following order:
    1. Class diagram
    2. Component diagram
    3. Sequence diagram
    
    If 'all' is selected, you MUST process each diagram type separately and strictly independently:
    1. First generate the class diagram, considering ONLY classes, interfaces, attributes, methods, and their relationships.
    2. Once completed, reset your context completely, clear previous diagram elements, and ONLY THEN
    generate the component diagram, strictly considering ONLY components, interfaces, packages, and their interactions.
    You must NOT reference classes or methods here.
    3. Again, reset your context completely, clear previous diagram elements, and ONLY THEN
    generate the sequence diagram, strictly focusing on participants, actors, messages, and activations
    without including elements from class or component diagrams.
    If you encounter an error during the generation of any diagram, regenerate only that specific diagram and NOT ALL.
    DO NOT mix elements or references between diagrams.
    Each diagram must be entirely self-contained and reflect ONLY its specified type of elements.
    If the diagram generation tool fails or produces an invalid file, you MUST review and correct
      the PlantUML code and retry generation until success.

    You must:
    - Include only the **most relevant interfaces/classes/components/participants** 
    - Do NOT include helper or annotation-only interfaces unless they are architecturally central.
    - Group elements into packages or namespaces where appropriate.
    - For class diagrams, show key method names and types (e.g., `getId(): Long`, `find(String): T`).
    - Include **relationships** between elements (e.g., inheritance, dependency, association).
    - Ensure each diagram is **structurally informative and visually compact** (avoid overwhelming size).
    - Strip out excessive whitespace or empty lines in the output.
    - When defining macros or reusable structures, **do not include comments inside macro parameters**,
      as they may cause syntax errors.
      Place any explanatory comments **outside** of macro definitions.
    - When creating components or diagram elements that will be referenced in relationships,
      **always assign an alias** to each element.
      Use the assigned alias in connections or relationships instead of the visual name.
      Example: define `component "Component Name" as CN`, then reference as `CN --> OtherComponentAlias : Uses`.
    - DO NOT INCLUDE inside the code block headings like '## Class Diagram', '## Component Diagram', or '## Sequence Diagram'

  inputs:
    diagram_type: "{diagram_type}"
    output_format: "{output_format}"

  diagram_rules:
    component:
      keyword: "component"
      allowed_elements: [ "component", "interface", "artifact", "ports", "package"]
      disallowed_elements: [ "class", "attributes", "methods", "tool", "agent"]
      description: >
        - Use the keyword `component` to represent high-level modules or services.
        - **Use `interface` for external dependencies or interactions**.
        - **Use `artifact` to represent files (e.g., `.py`, `.md`, `.svg`)**.
        - **Use `package` to logically group related components** (e.g., Agents, Tools, Memory).
        - **Do NOT list methods, attributes, or internal details** inside components.
        - Focus on **interactions and relationships** between components.
        - Represent dependencies using **interfaces (`interface`) or ports (`[ ]`)**.
        - Always assign an alias to components and use aliases in relationships.
          Example: `component "Repository-service" as RS`, then `RS --> RE : Uses`.

    class:
      keyword: "class"
      allowed_elements: ["class", "interface", "attributes", "methods"]
      disallowed_elements: ["component", "ports", "artifact"]
      description: >
        - Use the keyword `class` to represent classes, interfaces, or abstract classes.
        - Include **attributes and methods** inside each class.
        - Show **inheritance, associations, and dependencies**.

    sequential:
      keyword: "sequence"
      allowed_elements: ["actor", "participant", "message", "activation"]
      disallowed_elements: ["class", "component", "artifact"]
      description: >
        - Use the keyword `participant` to define entities before referencing them in messages.
        - Ensure all **actors, participants, and lifelines** are declared before usage.
        - Use `->` for synchronous messages and `-->` for asynchronous messages.
        - Always **match each `activate` with a corresponding `deactivate`** to avoid inconsistent activation flows.
        - Avoid **unsupported characters** (e.g., `/`, special symbols, or spaces) in participant names.
        - If a participant name contains special characters or spaces, use an **alias (`as`)** to assign a valid identifier.
        - Ensure messages follow the correct PlantUML syntax and are aligned with the sequence flow.
        - Do **not use `parallel`**, as it is **not supported in PlantUML sequence diagrams**.
        - To indicate parallel execution, use **`group`** instead (e.g., `group Parallel Execution`).
        - Maintain a clear **logical order of interactions** to avoid missing or redundant messages.

  expected_output: >
    PlantUML code that accurately represents the requested {diagram_type} diagram
    and is saved in {output_format} format, conforming to PlantUML syntax.
    If the {diagram_type} is 'all', output the diagrams sequentially, each preceded by a heading indicating the diagram type:
      ## Class Diagram
      (class diagram PlantUML code)
      ## Component Diagram
      (component diagram PlantUML code)
      ## Sequence Diagram
      (sequence diagram PlantUML code)

  validation_rules:
    - "IF `{diagram_type}` is 'class' and output contains `component`, reject and regenerate."
    - "IF `{diagram_type}` is 'component' and output contains `class` as a **PlantUML keyword**, reject and regenerate."
    - "IF `{diagram_type}` is 'component' and output contains `agent`, `task`, `tool`, or `memory`,
      ensure they are categorized under `package` or `interface`, not as `component`."
    - "IF `{diagram_type}` is 'component' and a file (ending in `.py`, `.md`, `.svg`) is defined as a `component`,
      convert it to an `artifact` instead of rejecting."
    - "IF `{diagram_type}` is 'sequence' AND `activate` has NO corresponding `deactivate`, reject and regenerate."
    - "IF `{diagram_type}` is 'sequence' AND a message points to an undefined `participant`, reject and regenerate."
    - "IF `{diagram_type}` is 'sequence' AND `parallel` is used, suggest `group Parallel Execution` instead."
    - "IF macros or reusable definitions are used, ensure no comments are present inside macro parameters to prevent syntax errors."
    - "IF `{diagram_type}` is 'component' AND any element is referenced in a relationship without an alias, reject and regenerate.
      Always define and use aliases for references."
    - "IF the PlantUML code contains headings like '## Class Diagram', '## Component Diagram', or '## Sequence Diagram'
      inside the code block, reject and regenerate."

  agent: code_diagramming_agent

aggregation_task :
  description: >
    Synthesize and consolidate the distributed analysis results from {len(results)} code chunks into a unified, comprehensive architectural assessment.
            
    **Source Analysis Results**: {results}
    
    **Consolidation Methodology:**
    
    **1. Cross-Chunk Pattern Synthesis**
    - Identify recurring architectural patterns, design principles, and coding conventions across all analyzed chunks
    - Correlate findings to establish system-wide architectural themes and design philosophy
    - Eliminate redundant observations while preserving unique insights from individual chunks
    - Validate pattern consistency and identify architectural deviations or inconsistencies
    
    **2. Holistic Architecture Reconstruction**
    - Synthesize individual chunk findings into a coherent, system-wide architectural overview
    - Map inter-chunk dependencies and component relationships to build complete system topology
    - Identify architectural layers, boundaries, and integration points across the entire codebase
    - Reconstruct the overall system design from distributed analysis fragments
    
    **3. Component Integration & Relationship Mapping**
    - Consolidate component inventories from all chunks into a unified system component catalog
    - Map cross-component dependencies and data flow patterns spanning multiple chunks
    - Identify system-wide integration patterns and communication mechanisms
    - Document component hierarchies and architectural boundaries at the system level
    
    **4. Quality & Technical Debt Aggregation**
    - Aggregate code quality metrics and technical debt indicators across all chunks
    - Identify system-wide quality trends and consistency patterns
    - Correlate quality issues to architectural decisions and design patterns
    - Prioritize technical debt based on system-wide impact and architectural significance
    
    **5. Strategic Insight Generation**
    - Synthesize chunk-level findings into strategic, system-level insights and recommendations
    - Identify opportunities for architectural improvements that span multiple components
    - Assess overall system maintainability, scalability, and evolution potential
    - Generate actionable recommendations based on comprehensive system understanding
    
    **Quality Assurance Requirements:**
    - Ensure no critical findings from individual chunks are lost in consolidation
    - Maintain traceability between consolidated insights and source chunk analyses
    - Validate that the consolidated analysis provides greater value than the sum of its parts
    - Focus on emergent properties and system-level characteristics not visible in individual chunks
  expected_output: >
    **Unified Architectural Analysis Report** providing comprehensive system-level insights:
            
    **1. Executive Architectural Summary**
    - **System Overview**: High-level description of the overall system architecture and design philosophy
    - **Architectural Paradigm**: Primary architectural style (Microservices, Monolithic, Layered, Event-Driven, etc.)
    - **Technology Coherence**: Assessment of technology stack consistency and integration quality
    - **Design Maturity**: Overall evaluation of architectural sophistication and best practices adoption
    
    **2. Consolidated Pattern Analysis**
    ```
    Design Patterns Identified: [List with frequency and implementation quality]
    Architectural Patterns: [System-wide patterns with consistency assessment]
    Anti-Patterns Detected: [Problematic patterns with system-wide impact]
    Pattern Consistency Score: [Percentage of consistent pattern implementation]
    ```
    
    **3. System Component Architecture**
    | Component Category | Components Count | Primary Responsibilities | Integration Quality | Technical Debt Level |
    |-------------------|------------------|------------------------|-------------------|-------------------|
    | [Business Logic]  | [Number]         | [Core Functions]       | [High/Med/Low]    | [High/Med/Low]    |
    | [Data Layer]      | [Number]         | [Data Management]      | [High/Med/Low]    | [High/Med/Low]    |
    | [Infrastructure]  | [Number]         | [System Services]      | [High/Med/Low]    | [High/Med/Low]    |
    
    **4. Cross-System Dependency Analysis**
    - **Dependency Complexity**: Assessment of overall system coupling and cohesion
    - **Integration Points**: Critical interfaces and communication patterns between major subsystems
    - **External Dependencies**: Third-party integrations and their architectural impact
    - **Circular Dependencies**: Identified architectural issues requiring attention
    
    **5. Aggregated Quality Metrics**
    ```
    Overall Maintainability Index: [Score/100]
    Average Cyclomatic Complexity: [Score with distribution]
    Technical Debt Ratio: [Percentage with hotspot identification]
    Code Coverage Assessment: [Estimated coverage gaps]
    Architecture Compliance Score: [Adherence to best practices]
    ```
    
    **6. Strategic Architectural Recommendations**
    
    **High Priority (Immediate Action Required):**
    - [Critical architectural issues requiring immediate attention]
    - [Security vulnerabilities with system-wide impact]
    - [Performance bottlenecks affecting system scalability]
    
    **Medium Priority (Next Development Cycle):**
    - [Structural improvements for better maintainability]
    - [Refactoring opportunities with significant impact]
    - [Technology upgrade recommendations]
    
    **Low Priority (Long-term Evolution):**
    - [Architectural enhancements for future scalability]
    - [Code quality improvements and standardization]
    - [Documentation and knowledge transfer improvements]
    
    **7. System Evolution Roadmap**
    - **Scalability Assessment**: Current architecture's ability to handle growth
    - **Maintainability Projection**: Long-term maintenance considerations
    - **Technology Migration Path**: Recommended technology evolution strategy
    - **Architectural Modernization**: Steps toward improved architectural patterns
    
    **8. Implementation Guidelines**
    - **Development Standards**: Recommended coding and architectural standards
    - **Quality Gates**: Suggested quality metrics and monitoring approaches  
    - **Architectural Governance**: Guidelines for maintaining architectural integrity
    - **Team Organization**: Recommended team structure for optimal system maintenance
    
    **Format**: Professional markdown report with executive summary, detailed analysis sections, quantitative metrics tables, 
    and actionable recommendations suitable for technical leadership and development teams.

  agent: batch_coordinator